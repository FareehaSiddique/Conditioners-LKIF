{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddbe358b-b846-4d11-b05d-1ce96625efd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ANOVA_Analysis_plots3.py\n",
    "#!/usr/bin/env python3\n",
    "\n",
    "\n",
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\n",
    "# Combined figure panels:\n",
    "# (1) ω² panels with Explained SD annotations (sqrt(AEV)) for two-way and three-way (T, SSR)\n",
    "# (2) Explained SD-only panels (sqrt(AEV)) for two-way and three-way (T, SSR)\n",
    "#\n",
    "# The code reads the provided Excel coupling tables and .mat time series,\n",
    "# computes |ΔIF|, bins by SM/VPD/T/SSR quartiles, runs ANOVA,\n",
    "# bootstraps CIs, and saves 400 dpi multi-panel PNGs. It also displays the figures inline.\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from pathlib import Path\n",
    "import scipy.io as sio\n",
    "\n",
    "# -------------------------\n",
    "# Global font size increase\n",
    "# -------------------------\n",
    "mpl.rcParams.update({\n",
    "    \"font.size\": 14,          # default/base text\n",
    "    \"axes.titlesize\": 14,     # subplot titles (unless overridden)\n",
    "    \"axes.labelsize\": 14,     # axis labels\n",
    "    \"xtick.labelsize\": 12,    # tick labels\n",
    "    \"ytick.labelsize\": 12,\n",
    "    \"legend.fontsize\": 12,\n",
    "})\n",
    "\n",
    "# -------------------------\n",
    "# Paths\n",
    "# -------------------------\n",
    "P_LAI_XLSX = Path(\"IF_Couplings_China_LAI.xlsx\")\n",
    "P_GPP_XLSX = Path(\"IF_Couplings_China_GPP.xlsx\")\n",
    "P_LAI_MAT  = Path(\"China_LAI.mat\")\n",
    "P_GPP_MAT  = Path(\"China_GPP.mat\")\n",
    "\n",
    "OUT_COMBO_W_SD = Path(\"Combined_ANOVA_omega2_with_SD.png\")\n",
    "OUT_COMBO_SD   = Path(\"Combined_ANOVA_SD_only.png\")\n",
    "\n",
    "# Bootstrap settings\n",
    "B = 400\n",
    "QS = (2.5, 97.5)\n",
    "RSEED = 20251108\n",
    "\n",
    "# -------------------------\n",
    "# Helpers\n",
    "# -------------------------\n",
    "def load_if_tables(p_lai, p_gpp):\n",
    "    lai = pd.read_excel(p_lai)\n",
    "    gpp = pd.read_excel(p_gpp)\n",
    "    def _fix_dates(df):\n",
    "        date_col = None\n",
    "        for cand in [\"date\", \"Date\", \"DATE\", \"Unnamed: 0\", \"time\", \"Time\"]:\n",
    "            if cand in df.columns:\n",
    "                date_col = cand\n",
    "                break\n",
    "        if date_col is None:\n",
    "            raise ValueError(\"Could not find a date column in IF table.\")\n",
    "        df = df.rename(columns={date_col: \"date\"})\n",
    "        df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "        return df\n",
    "    return _fix_dates(lai), _fix_dates(gpp)\n",
    "\n",
    "\n",
    "def find_col(cols, driver, target, conds=None):\n",
    "    base = f\"{driver}-{target}\".upper()\n",
    "    norm = [c.strip().upper() for c in cols]\n",
    "    if not conds:\n",
    "        for raw, up in zip(cols, norm):\n",
    "            if up.startswith(base) and (\"|\" not in up):\n",
    "                return raw\n",
    "        return None\n",
    "    want = set(s.strip().upper() for s in conds)\n",
    "    # exact-match of RHS tokens\n",
    "    for raw, up in zip(cols, norm):\n",
    "        if not up.startswith(base) or \"|\" not in up:\n",
    "            continue\n",
    "        rhs = up.split(\"|\", 1)[1].replace(\" \", \"\")\n",
    "        parts = set(p.strip().upper() for p in rhs.split(\",\") if p)\n",
    "        if parts == want:\n",
    "            return raw\n",
    "    # fallback: contains-all\n",
    "    for raw, up in zip(cols, norm):\n",
    "        if not up.startswith(base) or \"|\" not in up:\n",
    "            continue\n",
    "        if all(tok in up for tok in want):\n",
    "            return raw\n",
    "    return None\n",
    "\n",
    "\n",
    "def load_mat_series(p_mat, var_tokens, start_year):\n",
    "    mat = sio.loadmat(p_mat)\n",
    "    keys = [k for k in mat.keys() if not k.startswith(\"__\")]\n",
    "    chosen = None\n",
    "    for k in keys:\n",
    "        ok = True\n",
    "        for t in var_tokens:\n",
    "            if t.lower() not in k.lower():\n",
    "                ok = False\n",
    "                break\n",
    "        if ok and isinstance(mat[k], np.ndarray):\n",
    "            chosen = k\n",
    "            break\n",
    "    if chosen is None:\n",
    "        raise ValueError(f\"Could not find variable containing tokens {var_tokens} in {p_mat.name}. Keys sample: {keys[:12]}\")\n",
    "    arr = np.asarray(mat[chosen]).squeeze()\n",
    "    if arr.ndim == 2:\n",
    "        # collapse spatial dimension if present\n",
    "        arr = np.nanmean(arr, axis=1)\n",
    "    dates = pd.date_range(f\"{start_year}-01-01\", periods=arr.shape[0], freq=\"MS\")\n",
    "    return pd.Series(arr, index=dates, name=chosen)\n",
    "\n",
    "\n",
    "def quartile_bins(x):\n",
    "    s = pd.Series(x).astype(float)\n",
    "    ranks = pd.qcut(s, 4, labels=False, duplicates='drop')\n",
    "    return (ranks + 1).astype(int).to_numpy()\n",
    "\n",
    "\n",
    "def build_if_frame(df_if, group_label, driver, target, conds_all,\n",
    "                   sm_series, vpd_series, T_series, SSR_series):\n",
    "    col_bi = find_col(df_if.columns, driver, target, conds=None)\n",
    "    col_mv = find_col(df_if.columns, driver, target, conds=conds_all)\n",
    "    if col_bi is None or col_mv is None:\n",
    "        raise ValueError(f\"[{group_label}] Missing columns for {driver}-{target}|{','.join(conds_all)}\")\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        \"date\": df_if[\"date\"],\n",
    "        \"T_bi\": df_if[col_bi].astype(float).to_numpy(),\n",
    "        \"T_mv\": df_if[col_mv].astype(float).to_numpy(),\n",
    "    }).set_index(\"date\")\n",
    "\n",
    "    # align regimes\n",
    "    df[\"SM\"]  = sm_series.reindex(df.index).to_numpy()\n",
    "    df[\"VPD\"] = vpd_series.reindex(df.index).to_numpy()\n",
    "    df[\"T\"]   = T_series.reindex(df.index).to_numpy()\n",
    "    df[\"SSR\"] = SSR_series.reindex(df.index).to_numpy()\n",
    "\n",
    "    # bins\n",
    "    df[\"SM_q\"]  = quartile_bins(df[\"SM\"])\n",
    "    df[\"VPD_q\"] = quartile_bins(df[\"VPD\"])\n",
    "    df[\"T_q\"]   = quartile_bins(df[\"T\"])\n",
    "    df[\"SSR_q\"] = quartile_bins(df[\"SSR\"])\n",
    "\n",
    "    df[\"abs_dIF\"] = np.abs(df[\"T_bi\"] - df[\"T_mv\"])\n",
    "    df = df[[\"T_bi\",\"T_mv\",\"abs_dIF\",\"SM_q\",\"VPD_q\",\"T_q\",\"SSR_q\"]].dropna()\n",
    "    df[\"group\"] = group_label\n",
    "    return df.reset_index(drop=False)\n",
    "\n",
    "\n",
    "# ANOVA SS/df\n",
    "def ss_df_two_way(y, A, B):\n",
    "    y = np.asarray(y, float).reshape(-1)\n",
    "    A = np.asarray(A, int).reshape(-1)\n",
    "    B = np.asarray(B, int).reshape(-1)\n",
    "    mask = np.isfinite(y) & np.isfinite(A) & np.isfinite(B)\n",
    "    y = y[mask]; A = A[mask]; B = B[mask]\n",
    "    ybar = np.mean(y)\n",
    "    N = len(y)\n",
    "    SS_tot = np.sum((y - ybar)**2)\n",
    "\n",
    "    a_levels = np.unique(A); na = len(a_levels)\n",
    "    b_levels = np.unique(B); nb = len(b_levels)\n",
    "\n",
    "    SS_A = sum((A==a).sum() * (np.mean(y[A==a]) - ybar)**2 for a in a_levels)\n",
    "    SS_B = sum((B==b).sum() * (np.mean(y[B==b]) - ybar)**2 for b in b_levels)\n",
    "    SS_AB = 0.0\n",
    "    for a in a_levels:\n",
    "        for b in b_levels:\n",
    "            idx = (A==a)&(B==b)\n",
    "            if idx.any():\n",
    "                y_ab = np.mean(y[idx])\n",
    "                y_a  = np.mean(y[A==a])\n",
    "                y_b  = np.mean(y[B==b])\n",
    "                SS_AB += idx.sum() * (y_ab - y_a - y_b + ybar)**2\n",
    "\n",
    "    df_A  = na - 1\n",
    "    df_B  = nb - 1\n",
    "    df_AB = (na - 1) * (nb - 1)\n",
    "    df_tot = N - 1\n",
    "    df_err = max(df_tot - (df_A + df_B + df_AB), 1)\n",
    "\n",
    "    SS_err = SS_tot - SS_A - SS_B - SS_AB\n",
    "    return (SS_tot, SS_A, SS_B, SS_AB, SS_err,\n",
    "            df_A, df_B, df_AB, df_err)\n",
    "\n",
    "\n",
    "def ss_df_three_way(y, A, B, C):\n",
    "    y = np.asarray(y, float).reshape(-1)\n",
    "    A = np.asarray(A, int).reshape(-1)\n",
    "    B = np.asarray(B, int).reshape(-1)\n",
    "    C = np.asarray(C, int).reshape(-1)\n",
    "    mask = np.isfinite(y) & np.isfinite(A) & np.isfinite(B) & np.isfinite(C)\n",
    "    y = y[mask]; A = A[mask]; B = B[mask]; C = C[mask]\n",
    "    ybar = np.mean(y); N = len(y)\n",
    "    SS_tot = np.sum((y - ybar)**2)\n",
    "\n",
    "    a_levels = np.unique(A); na = len(a_levels)\n",
    "    b_levels = np.unique(B); nb = len(b_levels)\n",
    "    c_levels = np.unique(C); nc = len(c_levels)\n",
    "\n",
    "    mean_a = {a: np.mean(y[A==a]) for a in a_levels}\n",
    "    mean_b = {b: np.mean(y[B==b]) for b in b_levels}\n",
    "    mean_c = {c: np.mean(y[C==c]) for c in c_levels}\n",
    "    SS_A = sum((A==a).sum() * (mean_a[a] - ybar)**2 for a in a_levels)\n",
    "    SS_B = sum((B==b).sum() * (mean_b[b] - ybar)**2 for b in b_levels)\n",
    "    SS_C = sum((C==c).sum() * (mean_c[c] - ybar)**2 for c in c_levels)\n",
    "\n",
    "    mean_ab = {}\n",
    "    mean_ac = {}\n",
    "    mean_bc = {}\n",
    "    for a in a_levels:\n",
    "        for b in b_levels:\n",
    "            idx = (A==a)&(B==b)\n",
    "            if idx.any():\n",
    "                mean_ab[(a,b)] = np.mean(y[idx])\n",
    "    for a in a_levels:\n",
    "        for c in c_levels:\n",
    "            idx = (A==a)&(C==c)\n",
    "            if idx.any():\n",
    "                mean_ac[(a,c)] = np.mean(y[idx])\n",
    "    for b in b_levels:\n",
    "        for c in c_levels:\n",
    "            idx = (B==b)&(C==c)\n",
    "            if idx.any():\n",
    "                mean_bc[(b,c)] = np.mean(y[idx])\n",
    "\n",
    "    SS_AB = sum(((A==a)&(B==b)).sum() * (mean_ab[(a,b)] - mean_a[a] - mean_b[b] + ybar)**2\n",
    "                for a in a_levels for b in b_levels if (a,b) in mean_ab)\n",
    "    SS_AC = sum(((A==a)&(C==c)).sum() * (mean_ac[(a,c)] - mean_a[a] - mean_c[c] + ybar)**2\n",
    "                for a in a_levels for c in c_levels if (a,c) in mean_ac)\n",
    "    SS_BC = sum(((B==b)&(C==c)).sum() * (mean_bc[(b,c)] - mean_b[b] - mean_c[c] + ybar)**2\n",
    "                for b in b_levels for c in c_levels if (b,c) in mean_bc)\n",
    "\n",
    "    SS_ABC = 0.0\n",
    "    for a in a_levels:\n",
    "        for b in b_levels:\n",
    "            for c in c_levels:\n",
    "                idx = (A==a) & (B==b) & (C==c)\n",
    "                n = idx.sum()\n",
    "                if n > 0:\n",
    "                    y_abc = np.mean(y[idx])\n",
    "                    pred = ( mean_a[a] + mean_b[b] + mean_c[c]\n",
    "                             - ybar\n",
    "                             + (mean_ab.get((a,b), ybar) - mean_a[a] - mean_b[b] + ybar)\n",
    "                             + (mean_ac.get((a,c), ybar) - mean_a[a] - mean_c[c] + ybar)\n",
    "                             + (mean_bc.get((b,c), ybar) - mean_b[b] - mean_c[c] + ybar) )\n",
    "                    resid = y_abc - pred\n",
    "                    SS_ABC += n * (resid**2)\n",
    "\n",
    "    df_A  = na - 1\n",
    "    df_B  = nb - 1\n",
    "    df_C  = nc - 1\n",
    "    df_AB = (na - 1) * (nb - 1)\n",
    "    df_AC = (na - 1) * (nc - 1)\n",
    "    df_BC = (nb - 1) * (nc - 1)\n",
    "    df_ABC= (na - 1) * (nb - 1) * (nc - 1)\n",
    "    df_tot= N - 1\n",
    "    df_err= max(df_tot - (df_A + df_B + df_C + df_AB + df_AC + df_BC + df_ABC), 1)\n",
    "\n",
    "    SS_err = SS_tot - (SS_A + SS_B + SS_C + SS_AB + SS_AC + SS_BC + SS_ABC)\n",
    "    return (SS_tot, SS_A, SS_B, SS_C, SS_AB, SS_AC, SS_BC, SS_ABC, SS_err,\n",
    "            df_A, df_B, df_C, df_AB, df_AC, df_BC, df_ABC, df_err)\n",
    "\n",
    "\n",
    "def omega_sq(SS_eff, df_eff, SS_err, df_err, SS_tot):\n",
    "    if df_err <= 0:\n",
    "        return np.nan\n",
    "    MS_err = SS_err / df_err\n",
    "    denom = SS_tot + MS_err\n",
    "    num = SS_eff - df_eff * MS_err\n",
    "    return max(0.0, num / denom) if denom > 0 else np.nan\n",
    "\n",
    "\n",
    "def within_cell_bootstrap_indices(groups, rng):\n",
    "    idxs = []\n",
    "    for gidx in groups:\n",
    "        gidx = np.asarray(gidx, int)\n",
    "        if gidx.size == 0:\n",
    "            continue\n",
    "        draw = rng.choice(gidx, size=gidx.size, replace=True)\n",
    "        idxs.append(draw)\n",
    "    if not idxs:\n",
    "        return np.array([], dtype=int)\n",
    "    return np.concatenate(idxs)\n",
    "\n",
    "\n",
    "def bootstrap_two_way(y, A, Bf, B=400, qs=(2.5,97.5), seed=0):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    y = np.asarray(y, float).reshape(-1)\n",
    "    A = np.asarray(A, int).reshape(-1)\n",
    "    Bf = np.asarray(Bf, int).reshape(-1)\n",
    "    mask = np.isfinite(y) & np.isfinite(A) & np.isfinite(Bf)\n",
    "    y = y[mask]; A = A[mask]; Bf = Bf[mask]\n",
    "\n",
    "    # Cells\n",
    "    a_levels = np.unique(A); b_levels = np.unique(Bf)\n",
    "    groups = [np.where((A==a)&(Bf==b))[0] for a in a_levels for b in b_levels]\n",
    "\n",
    "    # Point estimates\n",
    "    SS_tot, SS_A, SS_B, SS_AB, SS_err, df_A, df_B, df_AB, df_err = ss_df_two_way(y, A, Bf)\n",
    "    var_y = SS_tot / max(1, (len(y)-1))\n",
    "    wA = omega_sq(SS_A, df_A, SS_err, df_err, SS_tot)\n",
    "    wB = omega_sq(SS_B, df_B, SS_err, df_err, SS_tot)\n",
    "    wAB= omega_sq(SS_AB, df_AB, SS_err, df_err, SS_tot)\n",
    "    SD_A = np.sqrt(max(wA,0)*var_y) if np.isfinite(wA) else np.nan\n",
    "    SD_B = np.sqrt(max(wB,0)*var_y) if np.isfinite(wB) else np.nan\n",
    "    SD_AB= np.sqrt(max(wAB,0)*var_y) if np.isfinite(wAB) else np.nan\n",
    "\n",
    "    # Bootstrap arrays\n",
    "    b_wA = np.zeros(B); b_wB = np.zeros(B); b_wAB = np.zeros(B)\n",
    "    b_SD_A = np.zeros(B); b_SD_B = np.zeros(B); b_SD_AB = np.zeros(B)\n",
    "    for b in range(B):\n",
    "        idx = within_cell_bootstrap_indices(groups, rng)\n",
    "        if idx.size < 4:\n",
    "            b_wA[b]=b_wB[b]=b_wAB[b]=np.nan\n",
    "            b_SD_A[b]=b_SD_B[b]=b_SD_AB[b]=np.nan\n",
    "            continue\n",
    "        (SS_tot_b, SS_A_b, SS_B_b, SS_AB_b, SS_err_b,\n",
    "         df_A_b, df_B_b, df_AB_b, df_err_b) = ss_df_two_way(y[idx], A[idx], Bf[idx])\n",
    "        var_y_b = SS_tot_b / max(1, (idx.size-1))\n",
    "        wA_b = omega_sq(SS_A_b, df_A_b, SS_err_b, df_err_b, SS_tot_b)\n",
    "        wB_b = omega_sq(SS_B_b, df_B_b, SS_err_b, df_err_b, SS_tot_b)\n",
    "        wAB_b= omega_sq(SS_AB_b, df_AB_b, SS_err_b, df_err_b, SS_tot_b)\n",
    "        b_wA[b], b_wB[b], b_wAB[b] = wA_b, wB_b, wAB_b\n",
    "        b_SD_A[b] = np.sqrt(max(wA_b,0)*var_y_b) if np.isfinite(wA_b) else np.nan\n",
    "        b_SD_B[b] = np.sqrt(max(wB_b,0)*var_y_b) if np.isfinite(wB_b) else np.nan\n",
    "        b_SD_AB[b]= np.sqrt(max(wAB_b,0)*var_y_b) if np.isfinite(wAB_b) else np.nan\n",
    "\n",
    "    def ci(arr):\n",
    "        return (np.nanpercentile(arr, qs[0]), np.nanpercentile(arr, qs[1]))\n",
    "\n",
    "    return (\n",
    "        [wA, wB, wAB], [ci(b_wA), ci(b_wB), ci(b_wAB)],\n",
    "        [SD_A, SD_B, SD_AB], [ci(b_SD_A), ci(b_SD_B), ci(b_SD_AB)]\n",
    "    )\n",
    "\n",
    "\n",
    "def bootstrap_three_way(y, A, Bf, C, B=400, qs=(2.5,97.5), seed=0):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    y = np.asarray(y, float).reshape(-1)\n",
    "    A = np.asarray(A, int).reshape(-1)\n",
    "    Bf = np.asarray(Bf, int).reshape(-1)\n",
    "    C = np.asarray(C, int).reshape(-1)\n",
    "    mask = np.isfinite(y) & np.isfinite(A) & np.isfinite(Bf) & np.isfinite(C)\n",
    "    y = y[mask]; A = A[mask]; Bf = Bf[mask]; C = C[mask]\n",
    "\n",
    "    # Cells\n",
    "    a_levels = np.unique(A); b_levels = np.unique(Bf); c_levels = np.unique(C)\n",
    "    groups = [np.where((A==a)&(Bf==b)&(C==c))[0]\n",
    "              for a in a_levels for b in b_levels for c in c_levels]\n",
    "\n",
    "    # Point estimates\n",
    "    (SS_tot, SS_A, SS_B, SS_C, SS_AB, SS_AC, SS_BC, SS_ABC, SS_err,\n",
    "     df_A, df_B, df_C, df_AB, df_AC, df_BC, df_ABC, df_err) = ss_df_three_way(y, A, Bf, C)\n",
    "    var_y = SS_tot / max(1, (len(y)-1))\n",
    "\n",
    "    def _w(SS, df): return omega_sq(SS, df, SS_err, df_err, SS_tot)\n",
    "    ws = [_w(SS_A, df_A), _w(SS_B, df_B), _w(SS_C, df_C),\n",
    "          _w(SS_AB, df_AB), _w(SS_AC, df_AC), _w(SS_BC, df_BC), _w(SS_ABC, df_ABC)]\n",
    "    SDs = [np.sqrt(max(w,0)*var_y) if np.isfinite(w) else np.nan for w in ws]\n",
    "\n",
    "    # Bootstrap arrays\n",
    "    b_ws = [np.zeros(B) for _ in range(7)]\n",
    "    b_SDs= [np.zeros(B) for _ in range(7)]\n",
    "    for b in range(B):\n",
    "        idx = within_cell_bootstrap_indices(groups, rng)\n",
    "        if idx.size < 8:\n",
    "            for arr in b_ws + b_SDs: arr[b] = np.nan\n",
    "            continue\n",
    "        (SS_tot_b, SS_A_b, SS_B_b, SS_C_b, SS_AB_b, SS_AC_b, SS_BC_b, SS_ABC_b, SS_err_b,\n",
    "         df_A_b, df_B_b, df_C_b, df_AB_b, df_AC_b, df_BC_b, df_ABC_b, df_err_b) = ss_df_three_way(\n",
    "             y[idx], A[idx], Bf[idx], C[idx])\n",
    "        var_y_b = SS_tot_b / max(1, (idx.size-1))\n",
    "        def _wb(SS, df): return omega_sq(SS, df, SS_err_b, df_err_b, SS_tot_b)\n",
    "        wbs = [_wb(SS_A_b, df_A_b), _wb(SS_B_b, df_B_b), _wb(SS_C_b, df_C_b),\n",
    "               _wb(SS_AB_b, df_AB_b), _wb(SS_AC_b, df_AC_b), _wb(SS_BC_b, df_BC_b), _wb(SS_ABC_b, df_ABC_b)]\n",
    "        for i, w in enumerate(wbs):\n",
    "            b_ws[i][b]  = w\n",
    "            b_SDs[i][b] = np.sqrt(max(w,0)*var_y_b) if np.isfinite(w) else np.nan\n",
    "\n",
    "    def ci(arr): return (np.nanpercentile(arr, QS[0]), np.nanpercentile(arr, QS[1]))\n",
    "\n",
    "    ws_ci  = [ci(arr) for arr in b_ws]\n",
    "    SDs_ci = [ci(arr) for arr in b_SDs]\n",
    "    return ws, ws_ci, SDs, SDs_ci\n",
    "\n",
    "\n",
    "def bar_ci(ax, labels, means, cis, color, ylabel, title, ylim=None, annotate=None):\n",
    "    x = np.arange(len(labels))\n",
    "    bars = ax.bar(x, means, color=color)\n",
    "    lo = np.array([c[0] for c in cis]); hi = np.array([c[1] for c in cis])\n",
    "    m  = np.array(means, float)\n",
    "    yerr = np.vstack([np.maximum(m - lo, 0.0), np.maximum(hi - m, 0.0)])\n",
    "    ax.errorbar(x, m, yerr=yerr, fmt='none', capsize=3, color=\"k\", lw=1)\n",
    "    ax.set_xticks(x); ax.set_xticklabels(labels, rotation=25, ha='right')\n",
    "    if ylim is not None:\n",
    "        ax.set_ylim(*ylim)\n",
    "    ax.set_ylabel(ylabel)\n",
    "    ax.set_title(title, fontsize=10)\n",
    "    # You can re-enable SD text annotations here if you want\n",
    "    if annotate is not None:\n",
    "        ymax = ax.get_ylim()[1]\n",
    "        for xi, bi, txt in zip(x, bars, annotate):\n",
    "            y = bi.get_height()\n",
    "            # ax.text(xi, min(ymax*0.98, y + 0.04*(ylim[1] if ylim else 1.0)),\n",
    "            #         txt, ha='center', va='bottom', fontsize=8)\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# Load data\n",
    "# -------------------------\n",
    "lai_if, gpp_if = load_if_tables(P_LAI_XLSX, P_GPP_XLSX)\n",
    "\n",
    "SM_LAI  = load_mat_series(P_LAI_MAT, (\"SM\",\"China\"), 1981)\n",
    "VPD_LAI = load_mat_series(P_LAI_MAT, (\"VPD\",\"China\"), 1981)\n",
    "T_LAI   = load_mat_series(P_LAI_MAT, (\"T\",\"China\"), 1981)\n",
    "SSR_LAI = load_mat_series(P_LAI_MAT, (\"SSR\",\"China\"), 1981)\n",
    "\n",
    "SM_GPP  = load_mat_series(P_GPP_MAT, (\"SM\",\"China\"), 1982)\n",
    "VPD_GPP = load_mat_series(P_GPP_MAT, (\"VPD\",\"China\"), 1982)\n",
    "T_GPP   = load_mat_series(P_GPP_MAT, (\"T\",\"China\"), 1982)\n",
    "SSR_GPP = load_mat_series(P_GPP_MAT, (\"SSR\",\"China\"), 1982)\n",
    "\n",
    "conds_full = [\"VPD\",\"T\",\"SSR\"]\n",
    "\n",
    "df_SM_LAI  = build_if_frame(lai_if, \"SM→LAI\",  \"SM\",  \"LAI\", conds_full, SM_LAI, VPD_LAI, T_LAI, SSR_LAI)\n",
    "df_VPD_LAI = build_if_frame(lai_if, \"VPD→LAI\", \"VPD\", \"LAI\", conds_full, SM_LAI, VPD_LAI, T_LAI, SSR_LAI)\n",
    "df_SM_GPP  = build_if_frame(gpp_if, \"SM→GPP\",  \"SM\",  \"GPP\", conds_full, SM_GPP, VPD_GPP, T_GPP, SSR_GPP)\n",
    "df_VPD_GPP = build_if_frame(gpp_if, \"VPD→GPP\", \"VPD\", \"GPP\", conds_full, SM_GPP, VPD_GPP, T_GPP, SSR_GPP)\n",
    "\n",
    "datasets = [\n",
    "    (\"SM→LAI\",  df_SM_LAI),\n",
    "    (\"VPD→LAI\", df_VPD_LAI),\n",
    "    (\"SM→GPP\",  df_SM_GPP),\n",
    "    (\"VPD→GPP\", df_VPD_GPP),\n",
    "]\n",
    "\n",
    "# -------------------------\n",
    "# Build combined figures\n",
    "# -------------------------\n",
    "row_panel_labels = [\"(a)\", \"(b)\", \"(c)\"]\n",
    "col_titles = [d[0] for d in datasets]  # [\"SM→LAI\", \"VPD→LAI\", \"SM→GPP\", \"VPD→GPP\"]\n",
    "\n",
    "# (1) ω² with SD annotations (sqrt(AEV))\n",
    "fig_wsd, axes_wsd = plt.subplots(3, 4, figsize=(16, 10), constrained_layout=True)\n",
    "\n",
    "for col, (title, df) in enumerate(datasets):\n",
    "    # Two-way\n",
    "    w_means, w_cis, sd_means, sd_cis = bootstrap_two_way(\n",
    "        df[\"abs_dIF\"].to_numpy(), df[\"SM_q\"].to_numpy(), df[\"VPD_q\"].to_numpy(),\n",
    "        B=B, qs=QS, seed=RSEED\n",
    "    )\n",
    "    labels = [\"SM\", \"VPD\", \"SM×VPD\"]\n",
    "    ax = axes_wsd[0, col]\n",
    "    bar_ci(ax, labels, w_means, w_cis, color=\"#4C72B0\",\n",
    "           ylabel=\"ω² (95% CI)\", title=\"\", ylim=(0,1),\n",
    "           annotate=[f\"SD={v:.3f}\" for v in sd_means])\n",
    "    ax.set_title(col_titles[col], fontsize=14)\n",
    "\n",
    "    # Three-way with T\n",
    "    w_means, w_cis, sd_means, sd_cis = bootstrap_three_way(\n",
    "        df[\"abs_dIF\"].to_numpy(), df[\"SM_q\"].to_numpy(), df[\"VPD_q\"].to_numpy(), df[\"T_q\"].to_numpy(),\n",
    "        B=B, qs=QS, seed=RSEED\n",
    "    )\n",
    "    labels = [\"SM\", \"VPD\", \"T\", \"SM×VPD\", \"SM×T\", \"VPD×T\", \"SM×VPD×T\"]\n",
    "    ax = axes_wsd[1, col]\n",
    "    bar_ci(ax, labels, w_means, w_cis, color=\"#4C72B0\",\n",
    "           ylabel=\"ω² (95% CI)\", title=\"\", ylim=(0,1),\n",
    "           annotate=[f\"SD={v:.3f}\" for v in sd_means])\n",
    "\n",
    "    # Three-way with SSR\n",
    "    w_means, w_cis, sd_means, sd_cis = bootstrap_three_way(\n",
    "        df[\"abs_dIF\"].to_numpy(), df[\"SM_q\"].to_numpy(), df[\"VPD_q\"].to_numpy(), df[\"SSR_q\"].to_numpy(),\n",
    "        B=B, qs=QS, seed=RSEED\n",
    "    )\n",
    "    labels = [\"SM\", \"VPD\", \"SSR\", \"SM×VPD\", \"SM×SSR\", \"VPD×SSR\", \"SM×VPD×SSR\"]\n",
    "    ax = axes_wsd[2, col]\n",
    "    bar_ci(ax, labels, w_means, w_cis, color=\"#4C72B0\",\n",
    "           ylabel=\"ω² (95% CI)\", title=\"\", ylim=(0,1),\n",
    "           annotate=[f\"SD={v:.3f}\" for v in sd_means])\n",
    "\n",
    "# Add row labels (a), (b), (c) at top-left of each row\n",
    "for r in range(3):\n",
    "    ax_row = axes_wsd[r, 0]\n",
    "    ax_row.text(-0.15, 1.05, row_panel_labels[r],\n",
    "                transform=ax_row.transAxes,\n",
    "                fontsize=16, fontweight='bold',\n",
    "                ha='right', va='bottom')\n",
    "\n",
    "fig_wsd.savefig(OUT_COMBO_W_SD, dpi=400, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "# (2) SD-only (sqrt(AEV)) — y-axis label only on the leftmost subplot of each row\n",
    "YLAB_SD = \"Explained SD of |ΔIF| (95% CI)\"\n",
    "SD_COLOR = \"#ea841e\"\n",
    "\n",
    "fig_sd, axes_sd = plt.subplots(3, 4, figsize=(16, 10), constrained_layout=True)\n",
    "\n",
    "for col, (title, df) in enumerate(datasets):\n",
    "    # Two-way\n",
    "    w_means, w_cis, sd_means, sd_cis = bootstrap_two_way(\n",
    "        df[\"abs_dIF\"].to_numpy(), df[\"SM_q\"].to_numpy(), df[\"VPD_q\"].to_numpy(),\n",
    "        B=B, qs=QS, seed=RSEED\n",
    "    )\n",
    "    labels = [\"SM\", \"VPD\", \"SM×VPD\"]\n",
    "    ax = axes_sd[0, col]\n",
    "    bar_ci(ax, labels, sd_means, sd_cis, color=SD_COLOR,\n",
    "           ylabel=(YLAB_SD if col == 0 else \"\"), title=\"\")\n",
    "    ax.set_title(col_titles[col], fontsize=14)\n",
    "\n",
    "    # Three-way with T\n",
    "    w_means, w_cis, sd_means, sd_cis = bootstrap_three_way(\n",
    "        df[\"abs_dIF\"].to_numpy(), df[\"SM_q\"].to_numpy(), df[\"VPD_q\"].to_numpy(), df[\"T_q\"].to_numpy(),\n",
    "        B=B, qs=QS, seed=RSEED\n",
    "    )\n",
    "    labels = [\"SM\", \"VPD\", \"T\", \"SM×VPD\", \"SM×T\", \"VPD×T\", \"SM×VPD×T\"]\n",
    "    ax = axes_sd[1, col]\n",
    "    bar_ci(ax, labels, sd_means, sd_cis, color=SD_COLOR,\n",
    "           ylabel=(YLAB_SD if col == 0 else \"\"), title=\"\")\n",
    "\n",
    "    # Three-way with SSR\n",
    "    w_means, w_cis, sd_means, sd_cis = bootstrap_three_way(\n",
    "        df[\"abs_dIF\"].to_numpy(), df[\"SM_q\"].to_numpy(), df[\"VPD_q\"].to_numpy(), df[\"SSR_q\"].to_numpy(),\n",
    "        B=B, qs=QS, seed=RSEED\n",
    "    )\n",
    "    labels = [\"SM\", \"VPD\", \"SSR\", \"SM×VPD\", \"SM×SSR\", \"VPD×SSR\", \"SM×VPD×SSR\"]\n",
    "    ax = axes_sd[2, col]\n",
    "    bar_ci(ax, labels, sd_means, sd_cis, color=SD_COLOR,\n",
    "           ylabel=(YLAB_SD if col == 0 else \"\"), title=\"\")\n",
    "\n",
    "# Row labels for SD-only figure as well (moved left/up to avoid the y-axis label)\n",
    "for r in range(3):\n",
    "    ax_row = axes_sd[r, 0]\n",
    "    ax_row.text(-0.07, 1.08, row_panel_labels[r],\n",
    "                transform=ax_row.transAxes,\n",
    "                fontsize=16, fontweight='bold',\n",
    "                ha='right', va='bottom', clip_on=False)\n",
    "\n",
    "fig_sd.savefig(OUT_COMBO_SD, dpi=400, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "print(\"Saved 400 dpi:\")\n",
    "print(f\" - {OUT_COMBO_W_SD}\")\n",
    "print(f\" - {OUT_COMBO_SD}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
